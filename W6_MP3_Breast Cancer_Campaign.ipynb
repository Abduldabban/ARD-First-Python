{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da8a143f",
   "metadata": {},
   "source": [
    "# Week 6, Mini Project 3, Breast Cancer Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f4dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595c10d9",
   "metadata": {},
   "source": [
    "# 1. Reading the Dataset\n",
    "Load the previously pre-processed Breast Cancer dataset saved in the CSV file “data_refined.csv” into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b36bb013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>2.255747</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.868652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>-0.398008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>4.910919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>-0.562450</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>2.110995</td>\n",
       "      <td>0.721473</td>\n",
       "      <td>2.060786</td>\n",
       "      <td>2.343856</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>1.947285</td>\n",
       "      <td>2.320965</td>\n",
       "      <td>-0.312589</td>\n",
       "      <td>-0.931027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>1.752563</td>\n",
       "      <td>2.015301</td>\n",
       "      <td>0.378365</td>\n",
       "      <td>-0.273318</td>\n",
       "      <td>0.664512</td>\n",
       "      <td>1.629151</td>\n",
       "      <td>-1.360158</td>\n",
       "      <td>-0.709091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1.704854</td>\n",
       "      <td>2.085134</td>\n",
       "      <td>1.615931</td>\n",
       "      <td>1.723842</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>1.263669</td>\n",
       "      <td>-0.217664</td>\n",
       "      <td>-1.058611</td>\n",
       "      <td>...</td>\n",
       "      <td>2.047399</td>\n",
       "      <td>1.421940</td>\n",
       "      <td>1.494959</td>\n",
       "      <td>-0.691230</td>\n",
       "      <td>-0.394820</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>0.733827</td>\n",
       "      <td>-0.531855</td>\n",
       "      <td>-0.973978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.702284</td>\n",
       "      <td>2.045574</td>\n",
       "      <td>0.672676</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>-0.840484</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>-0.809117</td>\n",
       "      <td>-0.895587</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374854</td>\n",
       "      <td>0.579001</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>-0.809587</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.414069</td>\n",
       "      <td>-1.104549</td>\n",
       "      <td>-0.318409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1.838341</td>\n",
       "      <td>2.336457</td>\n",
       "      <td>1.982524</td>\n",
       "      <td>1.735218</td>\n",
       "      <td>1.525767</td>\n",
       "      <td>3.272144</td>\n",
       "      <td>3.296944</td>\n",
       "      <td>2.658866</td>\n",
       "      <td>2.137194</td>\n",
       "      <td>1.043695</td>\n",
       "      <td>...</td>\n",
       "      <td>2.237926</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>1.653171</td>\n",
       "      <td>1.430427</td>\n",
       "      <td>3.904848</td>\n",
       "      <td>3.197605</td>\n",
       "      <td>2.289985</td>\n",
       "      <td>1.919083</td>\n",
       "      <td>2.219635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-1.808401</td>\n",
       "      <td>1.221792</td>\n",
       "      <td>-1.814389</td>\n",
       "      <td>-1.347789</td>\n",
       "      <td>-3.112085</td>\n",
       "      <td>-1.150752</td>\n",
       "      <td>-1.114873</td>\n",
       "      <td>-1.261820</td>\n",
       "      <td>-0.820070</td>\n",
       "      <td>-0.561032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764190</td>\n",
       "      <td>-1.432735</td>\n",
       "      <td>-1.075813</td>\n",
       "      <td>-1.859019</td>\n",
       "      <td>-1.207552</td>\n",
       "      <td>-1.305831</td>\n",
       "      <td>-1.745063</td>\n",
       "      <td>-0.048138</td>\n",
       "      <td>-0.751207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0       1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
       "1       1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
       "2       1.579888      0.456187        1.566503   1.558884         0.942210   \n",
       "3      -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
       "4       1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564     2.110995      0.721473        2.060786   2.343856         1.041842   \n",
       "565     1.704854      2.085134        1.615931   1.723842         0.102458   \n",
       "566     0.702284      2.045574        0.672676   0.577953        -0.840484   \n",
       "567     1.838341      2.336457        1.982524   1.735218         1.525767   \n",
       "568    -1.808401      1.221792       -1.814389  -1.347789        -3.112085   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0            3.283515        2.652874             2.532475       2.217515   \n",
       "1           -0.487072       -0.023846             0.548144       0.001392   \n",
       "2            1.052926        1.363478             2.037231       0.939685   \n",
       "3            3.402909        1.915897             1.451707       2.867383   \n",
       "4            0.539340        1.371011             1.428493      -0.009560   \n",
       "..                ...             ...                  ...            ...   \n",
       "564          0.219060        1.947285             2.320965      -0.312589   \n",
       "565         -0.017833        0.693043             1.263669      -0.217664   \n",
       "566         -0.038680        0.046588             0.105777      -0.809117   \n",
       "567          3.272144        3.296944             2.658866       2.137194   \n",
       "568         -1.150752       -1.114873            -1.261820      -0.820070   \n",
       "\n",
       "     fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0                  2.255747  ...      -1.359293         2.303601    2.001237   \n",
       "1                 -0.868652  ...      -0.369203         1.535126    1.890489   \n",
       "2                 -0.398008  ...      -0.023974         1.347475    1.456285   \n",
       "3                  4.910919  ...       0.133984        -0.249939   -0.550021   \n",
       "4                 -0.562450  ...      -1.466770         1.338539    1.220724   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564               -0.931027  ...       0.117700         1.752563    2.015301   \n",
       "565               -1.058611  ...       2.047399         1.421940    1.494959   \n",
       "566               -0.895587  ...       1.374854         0.579001    0.427906   \n",
       "567                1.043695  ...       2.237926         2.303601    1.653171   \n",
       "568               -0.561032  ...       0.764190        -1.432735   -1.075813   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0            1.307686           2.616665         2.109526   \n",
       "1           -0.375612          -0.430444        -0.146749   \n",
       "2            0.527407           1.082932         0.854974   \n",
       "3            3.394275           3.893397         1.989588   \n",
       "4            0.220556          -0.313395         0.613179   \n",
       "..                ...                ...              ...   \n",
       "564          0.378365          -0.273318         0.664512   \n",
       "565         -0.691230          -0.394820         0.236573   \n",
       "566         -0.809587           0.350735         0.326767   \n",
       "567          1.430427           3.904848         3.197605   \n",
       "568         -1.859019          -1.207552        -1.305831   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  diagnosis  \n",
       "0                2.296076        2.750622                 1.937015          1  \n",
       "1                1.087084       -0.243890                 0.281190          1  \n",
       "2                1.955000        1.152255                 0.201391          1  \n",
       "3                2.175786        6.046041                 4.935010          1  \n",
       "4                0.729259       -0.868353                -0.397100          1  \n",
       "..                    ...             ...                      ...        ...  \n",
       "564              1.629151       -1.360158                -0.709091          1  \n",
       "565              0.733827       -0.531855                -0.973978          1  \n",
       "566              0.414069       -1.104549                -0.318409          1  \n",
       "567              2.289985        1.919083                 2.219635          1  \n",
       "568             -1.745063       -0.048138                -0.751207          0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_data_refined = pd.read_csv('data_refined.csv') # read the data_refined dataset\n",
    "df_data_refined.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "\n",
    "df_data_refined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46dfc15",
   "metadata": {},
   "source": [
    "# 2. Splitting the Data\n",
    "Split your data as follows: \\\n",
    "80% training set \\\n",
    "10% validation set \\\n",
    "10% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f4ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = len(df_data_refined.columns)\n",
    "\n",
    "x = df_data_refined.iloc[:,0:columns-1].values\n",
    "\n",
    "y = df_data_refined.diagnosis.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d88cb0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455 114 455 114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "print(len(x_train), len(x_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e37f068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 57 57 57\n"
     ]
    }
   ],
   "source": [
    "x_test, x_validate, y_test, y_validate = train_test_split(x_test, y_test, test_size = 0.5, random_state = 0)\n",
    "print(len(x_test), len(x_validate), len(y_test), len(y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10fcfc",
   "metadata": {},
   "source": [
    "# 3. Classification Using Artificial Neural Networks\n",
    "Use the Scikit-Learn Multi-Layer Perceptron (MLP) Classifier. \\\n",
    "Train your dataset. \\\n",
    "Get accuracy scores and confusion matrix. \\\n",
    "You need a minimum accuracy score of 94%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3acbf708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(batch_size=20, hidden_layer_sizes=(100, 100, 100), max_iter=100,\n",
       "              random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "modelMLPC=MLPClassifier(hidden_layer_sizes=(100,100,100,), activation='relu', solver='adam',\n",
    "                        batch_size=20, max_iter=100, random_state=0)\n",
    "\n",
    "modelMLPC.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8521a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predMLPC=modelMLPC.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e212ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit Learn MLPClassifier accuracy score with testing data: 98.24561403508771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Scikit Learn MLPClassifier accuracy score with testing data: ' + str(accuracy_score(y_test,y_predMLPC)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46f2d7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit Learn MLPclassifier confusion matrix \n",
      " [[34  1]\n",
      " [ 0 22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrixMLPC = confusion_matrix(y_test, y_predMLPC)\n",
    "\n",
    "print('Scikit Learn MLPclassifier confusion matrix \\n', confusion_matrixMLPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e284c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit Learn MLPClassifier accuracy score with validation data: 98.24561403508771\n"
     ]
    }
   ],
   "source": [
    "# using validation data\n",
    "\n",
    "y_predMLPC=modelMLPC.predict(x_validate)\n",
    "\n",
    "print('Scikit Learn MLPClassifier accuracy score with validation data: ' + str(accuracy_score(y_validate,y_predMLPC)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1bf3b0",
   "metadata": {},
   "source": [
    "Build another neural network using Keras. \\\n",
    "Re-train your dataset. \\\n",
    "Get accuracy scores and confusion matrix. \\\n",
    "Compare results with the outputs of the classifiers in through project 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc67c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "#Adding Input Layer\n",
    "from keras.layers import Dense\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "# Add two fully connected layers \n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "#Adding Output Layer\n",
    "model.add(Dense(units=1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9db4d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45fdab71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 0.2052 - accuracy: 0.9429\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1281 - accuracy: 0.9802\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1230 - accuracy: 0.9846\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1135 - accuracy: 0.9890\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.9934\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1072 - accuracy: 0.9934\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.9934\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.9934\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1035 - accuracy: 0.9934\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9934\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9934\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.9934\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.9934\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1020 - accuracy: 0.9934\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1024 - accuracy: 0.9934\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1021 - accuracy: 0.9934\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.9934\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1018 - accuracy: 0.9934\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21dad1c0a90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=20, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de338f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_predKERAS=model.predict(x_test)\n",
    "\n",
    "y_predKERAS=(y_predKERAS>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22e09aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model accuracy score with testing data: 96.49122807017544\n"
     ]
    }
   ],
   "source": [
    "print('Keras model accuracy score with testing data: ' + str(accuracy_score(y_test,y_predKERAS)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30565319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model confusion matrix \n",
      " [[34  1]\n",
      " [ 1 21]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_predKERAS)\n",
    "\n",
    "print('Keras model confusion matrix \\n', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "754104ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "Keras model accuracy score with validation data: 98.24561403508771\n"
     ]
    }
   ],
   "source": [
    "# using validation data\n",
    "\n",
    "y_predKERAS=model.predict(x_validate)\n",
    "\n",
    "y_predKERAS=(y_predKERAS>0.5)\n",
    "\n",
    "print('Keras model accuracy score with validation data: ' + str(accuracy_score(y_validate,y_predKERAS)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad1c0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras produced higher score in training data. However with unknown data - testing and validation MLP Classifier performed better\n",
    "\n",
    "# However, both produced more than 94% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb82a5",
   "metadata": {},
   "source": [
    "# 4. Reading the Dataset\n",
    "\n",
    "Load the previously pre-processed Insurance dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea686a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charges</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16884.92400</td>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1725.55230</td>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4449.46200</td>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21984.47061</td>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3866.85520</td>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>10600.54830</td>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>2205.98080</td>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>1629.83350</td>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>2007.94500</td>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>29141.36030</td>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          charges  age     bmi  children  sex_male  smoker_yes  \\\n",
       "0     16884.92400   19  27.900         0         0           1   \n",
       "1      1725.55230   18  33.770         1         1           0   \n",
       "2      4449.46200   28  33.000         3         1           0   \n",
       "3     21984.47061   33  22.705         0         1           0   \n",
       "4      3866.85520   32  28.880         0         1           0   \n",
       "...           ...  ...     ...       ...       ...         ...   \n",
       "1333  10600.54830   50  30.970         3         1           0   \n",
       "1334   2205.98080   18  31.920         0         0           0   \n",
       "1335   1629.83350   18  36.850         0         0           0   \n",
       "1336   2007.94500   21  25.800         0         0           0   \n",
       "1337  29141.36030   61  29.070         0         0           1   \n",
       "\n",
       "      region_northwest  region_southeast  region_southwest  \n",
       "0                    0                 0                 1  \n",
       "1                    0                 1                 0  \n",
       "2                    0                 1                 0  \n",
       "3                    1                 0                 0  \n",
       "4                    1                 0                 0  \n",
       "...                ...               ...               ...  \n",
       "1333                 1                 0                 0  \n",
       "1334                 0                 0                 0  \n",
       "1335                 0                 1                 0  \n",
       "1336                 0                 0                 1  \n",
       "1337                 1                 0                 0  \n",
       "\n",
       "[1338 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_insurance = pd.read_csv('df_insurance.csv') # read the preprocessed insurance dataset\n",
    "\n",
    "df_insurance.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "\n",
    "df_insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d2005b",
   "metadata": {},
   "source": [
    "# 5. Splitting the Data\n",
    "Split your data as follows: \\\n",
    "80% training set \\\n",
    "10% validation set \\\n",
    "10% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8debc309",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = len(df_insurance.columns)\n",
    "\n",
    "x = df_insurance.iloc[:,1:columns].values\n",
    "\n",
    "y = df_insurance.charges.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff72ccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1070 268 1070 268\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "print(len(x_train), len(x_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17a7cb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 134 134 134\n"
     ]
    }
   ],
   "source": [
    "x_test, x_validate, y_test, y_validate = train_test_split(x_test, y_test, test_size = 0.5, random_state = 0)\n",
    "print(len(x_validate), len(x_test), len(y_validate), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f556a",
   "metadata": {},
   "source": [
    "# 6. Regression Using Artificial Neural Networks:\n",
    "Use the Scikit-Learn Multi-Layer Perceptron (MLP) Regression. \\\n",
    "Fit your dataset. \\\n",
    "Get r2 score. \\\n",
    "You need a minimum r2 score of 82%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dd92118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(batch_size=10, hidden_layer_sizes=(200, 200, 200), max_iter=100,\n",
       "             random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "modelMLPR=MLPRegressor(hidden_layer_sizes=(200,200,200,), activation='relu', solver='adam',\n",
    "                        batch_size=10, max_iter=100, random_state=0)\n",
    "\n",
    "modelMLPR.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c091726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit Learn MLPRegressor score with testing data:  89.10051584251006\n"
     ]
    }
   ],
   "source": [
    "scoreMLPR=modelMLPR.score(x_test, y_test)\n",
    "\n",
    "print('Scikit Learn MLPRegressor score with testing data: ', scoreMLPR*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da681c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit Learn MLPRegressor score with testing data:  77.52673602433677\n"
     ]
    }
   ],
   "source": [
    "scoreMLPR=modelMLPR.score(x_validate, y_validate)\n",
    "\n",
    "print('Scikit Learn MLPRegressor score with testing data: ', scoreMLPR*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0908c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31f90796",
   "metadata": {},
   "source": [
    "Build another neural network using Keras. \\\n",
    "Re-train your dataset. \\\n",
    "Get r2 score. \\\n",
    "Compare results with the outputs of the regressors in through project 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40156033",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKR=Sequential()\n",
    "\n",
    "#Adding Input Layer\n",
    "modelKR.add(Dense(units=200, activation='relu'))\n",
    "\n",
    "# Add two fully connected layers \n",
    "modelKR.add(Dense(units=200, activation='relu'))\n",
    "modelKR.add(Dense(units=200, activation='relu'))\n",
    "\n",
    "#Adding Output Layer\n",
    "modelKR.add(Dense(units=1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df59503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKR.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8325bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "107/107 [==============================] - 1s 4ms/step - loss: 220671296.0000 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 127755040.0000 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 126722368.0000 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 125178440.0000 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 124390712.0000 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 121647136.0000 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 119378064.0000 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 115084192.0000 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 111660032.0000 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 107006368.0000 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 96864312.0000 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 82332856.0000 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 65077784.0000 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 51124708.0000 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 44318840.0000 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 40874880.0000 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 41912660.0000 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 40552940.0000 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 40603248.0000 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 39799848.0000 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 38179044.0000 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 38329108.0000 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 38868424.0000 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 39196952.0000 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 38121916.0000 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 37674496.0000 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 37820096.0000 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 36788820.0000 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 38601328.0000 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 36339276.0000 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 36560824.0000 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 36770660.0000 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 36793600.0000 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 35866044.0000 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 36250352.0000 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 35281296.0000 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 35547684.0000 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 35700064.0000 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 35122700.0000 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 35378892.0000 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 34873968.0000 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 35609212.0000 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 34305240.0000 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 34010216.0000 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 33915772.0000 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 33773328.0000 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 34032484.0000 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 33647128.0000 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 33817768.0000 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 33325742.0000 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 34175652.0000 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 33029156.0000 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 32830990.0000 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 32638402.0000 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 33031166.0000 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 32596382.0000 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 32278596.0000 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 32107838.0000 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 31940498.0000 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 31777444.0000 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 31888820.0000 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 31242880.0000 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 31734978.0000 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 31445398.0000 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 31108604.0000 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 31224250.0000 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 30952912.0000 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 31196592.0000 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 31315156.0000 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 30187514.0000 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 30051694.0000 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 30330574.0000 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 1s 6ms/step - loss: 29934428.0000 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 30130022.0000 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 30483362.0000 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 29904516.0000 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 30199784.0000 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 29748438.0000 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 29793058.0000 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 29426940.0000 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 29293678.0000 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 29223124.0000 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 29452526.0000 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 29321620.0000 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 29039386.0000 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 28434606.0000 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 29717650.0000 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 28425334.0000 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 28408726.0000 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 28735188.0000 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 28613440.0000 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 28270060.0000 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 28016786.0000 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 28736262.0000 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 27861052.0000 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 27831372.0000 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 27358498.0000 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 28150490.0000 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 27341942.0000 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 27173040.0000 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21db1c40880>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelKR.fit(x_train, y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d3dff71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 15576029.0000 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy=modelKR.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777fd636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
