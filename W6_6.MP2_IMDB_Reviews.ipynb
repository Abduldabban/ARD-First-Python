{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdba93bb",
   "metadata": {},
   "source": [
    "# Week 6, Section 6, Mini Project 2, IMDB Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b4ea63",
   "metadata": {},
   "source": [
    "# 1. Read the Dataset\n",
    "To use the dataset from Keras datasets, use these lines of code:\n",
    "\n",
    "from keras.datasets import imdb \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\", maxlen=130, num_words=6000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec8c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\", maxlen=130, num_words=6000) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb70175",
   "metadata": {},
   "source": [
    "# 2. Padding Your Sequences\n",
    "You need to have equal sequences for training; for, this you will apply padding. \\\n",
    "Write these lines of code to implement the padding needed:\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=130) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0451a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.preprocessing import sequence\n",
    "# x_train = sequence.pad_sequences(x_train, maxlen=130) \n",
    "\n",
    " #module 'keras.preprocessing.sequence' has no attribute 'pad_sequences' error message\n",
    "\n",
    "\n",
    "# used this code instead\n",
    "from keras.utils import pad_sequences \n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=130)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e88eed",
   "metadata": {},
   "source": [
    "# 3. Your Initial code should look like this:\n",
    "import numpy as np \\\n",
    "np_load_old = np.load \\\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8dda1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_load_old = np.load\n",
    "np.load = lambda a,*k: np_load_old(a, allow_pickle=True, *k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55b55d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.datasets import imdb\n",
    "#(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\", maxlen=130, num_words=6000)\n",
    "\n",
    "# TypeError: <lambda>() got an unexpected keyword argument 'allow_pickle'\n",
    "\n",
    "# since this step was done at the begining, so I skipped it, and to avoid the error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90232fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.preprocessing import sequence\n",
    "# x_train = sequence.pad_sequences(x_train, maxlen=130) \n",
    "\n",
    " #module 'keras.preprocessing.sequence' has no attribute 'pad_sequences'\n",
    "\n",
    "\n",
    "# used this code instead\n",
    "from keras.utils import pad_sequences \n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=130)\n",
    "\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470764e3",
   "metadata": {},
   "source": [
    "## Define an RNN with the following layers:\n",
    "An embedding layer with the following parameters: \\\n",
    "The input dimension is 6000. \\\n",
    "The output dimension is 128. \\\n",
    "The input length is 130. \\\n",
    "An LSTM layer with 32 units. \\\n",
    "A fully connected layer with the following parameters: \\\n",
    "Activation function is ReLU. \\\n",
    "The number of units is 20. \\\n",
    "A dropout layer with a dropout rate of 5%. \\\n",
    "A fully connected layer with the following parameters: \\\n",
    "Activation function is sigmoid. \\\n",
    "The number of units is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae826f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "from keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "\n",
    "model.add(Embedding(input_dim = 6000,\n",
    "                   output_dim = 128,\n",
    "                   input_length = 130))\n",
    "model.add(LSTM(units = 32))\n",
    "model.add(Dense(units = 20, activation = \"relu\"))\n",
    "model.add(Dropout(rate = 0.05))\n",
    "model.add(Dense(units = 1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d28a668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 130, 128)          768000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                20608     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                660       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 789,289\n",
      "Trainable params: 789,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a151306",
   "metadata": {},
   "source": [
    "# 4. Choosing Hyperparameters\n",
    "Build the network using the following parameters: \\\n",
    "Optimizer: Adam \\\n",
    "Loss function: binary_crossentropy \\\n",
    "Metrics: accuracy \\\n",
    "Epochs: 5 \\\n",
    "Batch size: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc157a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = \"binary_crossentropy\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c93143d",
   "metadata": {},
   "source": [
    "# 5. Training Network\n",
    "Use Keras to implement the network described and train your data. \\\n",
    "Note: your code should return the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ac8d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "62/62 [==============================] - 10s 97ms/step - loss: 0.5934 - accuracy: 0.6709\n",
      "Epoch 2/5\n",
      "62/62 [==============================] - 6s 95ms/step - loss: 0.2782 - accuracy: 0.8919\n",
      "Epoch 3/5\n",
      "62/62 [==============================] - 6s 100ms/step - loss: 0.1449 - accuracy: 0.9489\n",
      "Epoch 4/5\n",
      "62/62 [==============================] - 6s 95ms/step - loss: 0.0977 - accuracy: 0.9669\n",
      "Epoch 5/5\n",
      "62/62 [==============================] - 6s 99ms/step - loss: 0.0562 - accuracy: 0.9846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c231419b50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4473cda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 5s 21ms/step - loss: 0.0316 - accuracy: 0.9914\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "368d89bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27976\\3470561433.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f1938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
